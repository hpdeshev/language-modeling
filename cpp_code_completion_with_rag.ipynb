{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130975a-540c-4601-bcda-6b8528cf68b1",
   "metadata": {
    "id": "1130975a-540c-4601-bcda-6b8528cf68b1"
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain_classic.document_loaders import DirectoryLoader\n",
    "from langchain_classic.llms import HuggingFacePipeline\n",
    "from langchain_classic.vectorstores import FAISS\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import (\n",
    "  Language, RecursiveCharacterTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2d26c-3932-48e6-ade9-194d971b11b7",
   "metadata": {
    "id": "8ef2d26c-3932-48e6-ade9-194d971b11b7"
   },
   "source": [
    "# Demonstration of retrieval-augmented C++ code completion with pretrained Granite-3B-Code-Base-2K model\n",
    "\n",
    "## Introduction\n",
    "In this notebook is demonstrated how a [Granite-3B-Code-Base-2K](#Granite-3B-Code-Base-2K) model can be used for C++ code completion with [retrieval-augmented generation (RAG)](https://en.wikipedia.org/wiki/Retrieval-augmented_generation), based on *.cc* and *.h* files in a folder. The demonstrated method utilizes:\n",
    "- [LangChain](#LangChain) framework for development of applications powered by large language models;\n",
    "- [Facebook AI Similarity Search (FAISS)](#Facebook-AI-Similarity-Search) vector-based text similarity search;\n",
    "- [Hugging Face Transformers](#Hugging-Face-Transformers) deep learning library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f9141-c49a-4738-9117-3c108c4eb595",
   "metadata": {
    "id": "e79f9141-c49a-4738-9117-3c108c4eb595"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad24d5-93e2-42a2-82c5-b5b93eb67764",
   "metadata": {
    "id": "a5ad24d5-93e2-42a2-82c5-b5b93eb67764"
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "DATA_DIR = \"data\"\n",
    "CHUNK_SIZE = 240  # 3 * 80-char lines\n",
    "\n",
    "# Text Generation\n",
    "MAX_GEN_TOKENS = 100\n",
    "MODEL_NAME = \"ibm-granite/granite-3b-code-base-2k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3acecf-c807-489f-84aa-9fe953a6a5b5",
   "metadata": {
    "id": "1e3acecf-c807-489f-84aa-9fe953a6a5b5"
   },
   "source": [
    "## Dataset retrieval\n",
    "\n",
    "The dataset constitutes a `FAISS` vector database created from C++ code chunks extracted from C++ source and header files found under the `DATA_DIR` folder. The vectors are based on the default `HuggingFaceEmbeddings` embedding model.\n",
    "\n",
    "Only the best vector similarity match is retrieved from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7e1a5-ef93-421c-828b-957163d94f7c",
   "metadata": {
    "id": "41d7e1a5-ef93-421c-828b-957163d94f7c"
   },
   "outputs": [],
   "source": [
    "doc_loader = DirectoryLoader(DATA_DIR, glob=[\"**/*.cc\", \"**/*.h\"])\n",
    "docs = doc_loader.load()\n",
    "cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "  language=Language.CPP, chunk_size=CHUNK_SIZE, chunk_overlap=0\n",
    ")\n",
    "cpp_chunks = cpp_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(\n",
    "  cpp_chunks, HuggingFaceEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever(\n",
    "  search_type=\"similarity\", search_kwargs={\"k\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce0d69-23cc-4d43-8374-b1c0aeba4b21",
   "metadata": {
    "id": "54ce0d69-23cc-4d43-8374-b1c0aeba4b21"
   },
   "source": [
    "## Model\n",
    "\n",
    "The [Granite-3B-Code-Base-2K](#Granite-3B-Code-Base-2K) model is used via a [Hugging Face Transformers](#Hugging-Face-Transformers) text generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673abaaf-c937-410e-8aca-0584344f9824",
   "metadata": {
    "id": "673abaaf-c937-410e-8aca-0584344f9824"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "  model_id=MODEL_NAME,\n",
    "  task=\"text-generation\",\n",
    "  pipeline_kwargs={\"max_new_tokens\": MAX_GEN_TOKENS,\n",
    "                   \"return_full_text\": False},\n",
    "  device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46e1b0-6263-4c4e-b214-05814a9c5400",
   "metadata": {
    "id": "fe46e1b0-6263-4c4e-b214-05814a9c5400"
   },
   "source": [
    "## Testing\n",
    "\n",
    "For a comparison test, given a custom prompt, `RAG`-based code completion is compared with a plaintext-based code completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf06aaa-d0d7-4d3d-8901-45d91e98a32a",
   "metadata": {
    "id": "2cf06aaa-d0d7-4d3d-8901-45d91e98a32a"
   },
   "outputs": [],
   "source": [
    "class RagChainHandler(BaseCallbackHandler):\n",
    "  def on_llm_start(\n",
    "    self,\n",
    "    serialized: dict[str, Any],\n",
    "    prompts: list[str],\n",
    "    *,\n",
    "    run_id: UUID,\n",
    "    parent_run_id: UUID | None = None,\n",
    "    tags: list[str] | None = None,\n",
    "    metadata: dict[str, Any] | None = None,\n",
    "    **kwargs: Any,\n",
    "  ) -> Any:\n",
    "    print(f\"[ RAG PROMPT ]\\n\\n{prompts[0]}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def format_docs(docs: list[Document]) -> str:\n",
    "  return docs[0].page_content\n",
    "\n",
    "\n",
    "prompt = \"engine.StartGame\"\n",
    "rag_chain = (\n",
    "  retriever | format_docs | llm | StrOutputParser()\n",
    ")\n",
    "rag_chain = rag_chain.with_config(callbacks=[RagChainHandler()])\n",
    "print(f\"[ PROMPT ]\\n\\n{prompt}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"[ GENERATED ]\\n\\n{llm.invoke(prompt)}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"[ RAG GENERATED ]\\n\\n{rag_chain.invoke(prompt)}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wsqgzypFWVN9",
   "metadata": {
    "id": "wsqgzypFWVN9"
   },
   "source": [
    "## References\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### APA style for references\n",
    "American Psychological Association. (2022). Creating an APA Style reference list guide. https://apastyle.apa.org/instructional-aids/creating-reference-list.pdf\n",
    "\n",
    "American Psychological Association. (2024). APA Style common reference examples guide. https://apastyle.apa.org/instructional-aids/reference-examples.pdf\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Vector databases\n",
    "<a name=\"Facebook-AI-Similarity-Search\"></a>\n",
    "#### Facebook AI Similarity Search\n",
    "Douze, M., Guzhva, A., Deng, C., Johnson, J., Szilvasy, G., Mazar√©, P. E., Lomeli, M., Hosseini, L., & J√©gou, H. (2024). The Faiss library. ArXiv, abs/2401.08281. https://arxiv.org/abs/2401.08281\n",
    "\n",
    "Johnson, J., Douze, M., & J√©gou, H. (2019). Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3), 535-547. https://arxiv.org/abs/1702.08734\n",
    "- [FAISS - Wikipedia](https://en.wikipedia.org/wiki/FAISS)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Machine learning models\n",
    "<a name=\"Granite-3B-Code-Base-2K\"></a>\n",
    "#### Granite-3B-Code-Base-2K\n",
    "Mishra, M., Stallone, M., Zhang, G., Shen, Y., Prasad, A., Soria, A.M., Merler, M., Selvam, P., Surendran, S., Singh, S., Sethi, M., Dang, X., Li, P., Wu, K., Zawad, S., Coleman, A., White, M., Lewis, M., Pavuluri, R., Koyfman, Y., Lublinsky, B., Bayser, M.D., Abdelaziz, I., Basu, K., Agarwal, M., Zhou, Y., Johnson, C., Goyal, A., Patel, H., Shah, Y., Zerfos, P., Ludwig, H., Munawar, A., Crouse, M., Kapanipathi, P., Salaria, S., Calio, B., Wen, S., Seelam, S.R., Belgodere, B.M., Fonseca, C., Singhee, A., Desai, N., Cox, D.D., Puri, R., & Panda, R. (2024). Granite Code Models: A Family of Open Foundation Models for Code Intelligence. ArXiv, abs/2405.04324. https://arxiv.org/abs/2405.04324\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Guides and tutorials\n",
    "- [Introduction | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/introduction/)\n",
    "- [ibm-granite/granite-3b-code-base-2k ¬∑ Hugging Face](https://huggingface.co/ibm-granite/granite-3b-code-base-2k)\n",
    "- [Hugging Face - Documentation](https://huggingface.co/docs)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Libraries and frameworks\n",
    "<a name=\"Hugging-Face-Transformers\"></a>\n",
    "#### Hugging Face Transformers\n",
    "Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., & Rush, A. M. (2020). Transformers: State-of-the-Art Natural Language Processing [Conference paper]. 38‚Äì45. https://www.aclweb.org/anthology/2020.emnlp-demos.6\n",
    "- [Transformers](https://huggingface.co/docs/transformers/index)\n",
    "\n",
    "<a name=\"LangChain\"></a>\n",
    "#### LangChain\n",
    "Chase, H. (2022). LangChain [Computer software]. https://github.com/langchain-ai/langchain\n",
    "- [Introduction | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/introduction/)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
